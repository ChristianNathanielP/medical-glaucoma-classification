# -*- coding: utf-8 -*-
"""Submission Proyek Pertama - ML Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JapCdgr4xjbWZGKXxaYDPvcMyLbEWjh-

# Submission Proyek Pertama Machine Learning Terapan

**Klasifikasi Tingkat Keparahan Glioma Menggunakan Data Klinis dan Mutasi Genetik**
- Nama: Christian Nathaniel
- Email: christiannathanielp@gmail.com
- Username: cnginn03

## Import Depedencies
"""

!pip install ucimlrepo

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score

"""## Data Understanding

Dataset [Glioma Grading Clinical and Mutation Features](https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset) berasal dari UCI ML Repo
"""

from ucimlrepo import fetch_ucirepo

# fetch dataset
glioma_grading_clinical_and_mutation_features = fetch_ucirepo(id=759)

Features = glioma_grading_clinical_and_mutation_features.data.features
Target = glioma_grading_clinical_and_mutation_features.data.targets

"""Mengambil Features dan Target dari UCI ML Repo menggunakan properti dari library ucimlrepo yang diimport"""

# metadata
print(glioma_grading_clinical_and_mutation_features.metadata)

# variable information
print(glioma_grading_clinical_and_mutation_features.variables)

"""Dataset Glioma Grading Clinical and Mutation Features berisi data klinis dan mutasi genetik dari pasien glioma. Dataset ini digunakan untuk klasifikasi tingkat glioma:

- Target: Grade glioma (0 = LGG, 1 = GBM)
- Fitur: 20 fitur genetik mutasi (biner), 3 fitur klinis (Jenis kelamin, Usia saat diagnosis, Ras)
- Jumlah data: 839 pasien
- Tipe data: Tabular, multivariat, tanpa missing values

Tujuan Mendeteksi apakah pasien tergolong LGG atau GBM dengan fitur klinis dan mutasi untuk meningkatkan akurasi diagnosis dan mengurangi biaya tes molecular.
"""

df = pd.concat([Features, Target], axis=1)
df

"""Menggabungkan Features dan Target pada Dataset dan mengubahnya menjadi Pandas Dataframe"""

df.info()

"""Terdapat 24 kolom, tidak ada yang aneh pada tipe datanya. 20 Fitur genetik bertipe data int (1 dan 0)"""

print(f"Data Duplikat: {df.duplicated().sum()}")

"""Terdapat satu data duplikat yang nantinya akan dibersihkan di Preprocessing"""

df.isna().sum()

"""Tidak ada data kosong pada dataset, sesuai dengan yang tertulis pada metadata dataset ini."""

df.describe()

"""Data yang ada terlihat normal, tidak ada anomali data yang mencolok.

## Exploratory Data Analysis (EDA)
"""

numerical_continuous = ['Age_at_diagnosis']
categorical_nominal = ['Gender', 'Race']
categorical_binary = [
    'IDH1', 'TP53', 'ATRX', 'PTEN', 'EGFR', 'CIC', 'MUC16',
    'PIK3CA', 'NF1', 'PIK3R1', 'FUBP1', 'RB1', 'NOTCH1',
    'BCOR', 'CSMD3', 'SMARCA4', 'GRIN2A', 'IDH2', 'FAT4', 'PDGFRA'
]
target_col = 'Grade'

"""Memecah beberapa kolom ke dalam kategori tipe data, untuk mempermudah mengeksplor masing-masing kategori"""

fig, axes = plt.subplots(1, 2, figsize=(16, 5))
col = numerical_continuous[0]

sns.histplot(data=df, x=col, kde=True, bins=10, ax=axes[0], color="#35b779")
axes[0].set_title(f"Distribution of {col.replace('_', ' ').title()}")
axes[0].set_xlabel(col.replace("_", " ").title())
axes[0].set_ylabel("Frequency")

# Boxplot
sns.boxplot(data=df, x=col, ax=axes[1], color="#35b779")
axes[1].set_title(f"Boxplot of {col.replace('_', ' ').title()}")
axes[1].set_xlabel(col.replace("_", " ").title())
axes[1].set_ylabel("")

plt.tight_layout()
plt.show()

"""- Usia pasien saat diagnosis berkisar antara **15 hingga 90 tahun**
- Boxplot menunjukkan **tidak ada outlier ekstrem** yang mencolok.
"""

fig, axes = plt.subplots(1, 2, figsize=(16, 5))
axes = axes.flatten()

for i, col in enumerate(categorical_nominal):
    sns.countplot(data=df, x=col, ax=axes[i], palette='viridis', hue=col, legend=True)
    axes[i].set_title(f"Distribution of {col.replace('_', ' ').title()}")
    axes[i].set_xlabel(col.replace("_", " ").title())
    axes[i].set_ylabel("Count")

plt.tight_layout()
plt.show()

"""- Distribusi jenis kelamin cukup seimbang dengan sedikit lebih banyak **laki-laki (0)** dibanding **perempuan (1)**.
- Ras dominan adalah **white**, diikuti oleh **black or african american**, dan minoritas kecil adalah asian dan american indian or alaska native.
"""

fig, axes = plt.subplots(4, 5, figsize=(16, 10))
axes = axes.flatten()

for i, col in enumerate(categorical_binary):
    sns.countplot(data=df, x=col, ax=axes[i], palette='viridis', hue=col, legend=True)
    axes[i].set_title(f"Distribution of {col.replace('_', ' ').title()}")
    axes[i].set_xlabel(col.replace("_", " ").title())
    axes[i].set_ylabel("Count")

plt.tight_layout()
plt.show()

"""Semua fitur genetik berupa biner (0 = tidak mutasi, 1 = mutasi).

Mayoritas fitur memiliki lebih banyak kasus tidak mutasi (0) dibanding mutasi (1), menunjukkan mutasi relatif jarang pada beberapa gen.
"""

fig, ax = plt.subplots(figsize=(16, 5))

sns.countplot(x=target_col, data=df, ax=ax, palette='viridis', hue=target_col, legend=True)
ax.set_title(f"Distribution of {target_col}")
ax.set_xlabel(f"{target_col} (0 = LGG; 1 = GBM)")
ax.set_ylabel("Count")

for p in ax.patches:
    height = p.get_height()
    ax.text(
        x=p.get_x() + p.get_width() / 2,
        y=height + 5,
        s=f'{int(height)}',
        ha='center'
    )

plt.tight_layout()
plt.show()

"""Target terdiri dari dua kelas:
- 0: LGG (Lower Grade Glioma) sebanyak 487 pasien
- 1: GBM (Glioblastoma Multiforme) sebanyak 352 pasien

Data cukup seimbang untuk tugas klasifikasi.

## Data Preprocessing

Pada Data Preprocessing, proses yang dilakukan adalah:
- Menghapus data duplikat agar tidak memengaruhi hasil model.

- Melakukan encoding pada fitur kategorikal Race menggunakan LabelEncoder untuk mengubahnya menjadi nilai numerik.

- Memisahkan fitur (variabel independen) dan target (variabel dependen) untuk pemodelan.

- Membagi dataset menjadi data latih dan data uji dengan proporsi 80:20, menggunakan stratifikasi berdasarkan target untuk menjaga distribusi kelas.

- Melakukan standardisasi pada fitur numerik kontinyu menggunakan StandardScaler agar data memiliki skala yang seragam dan meningkatkan performa model.
"""

df.drop_duplicates(inplace=True)

label = LabelEncoder()
df['Race'] = label.fit_transform(df['Race'])

features = [col for col in df.columns if col != target_col]
X = df[features]
y = df[target_col]

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

scaler = StandardScaler()
X_train[numerical_continuous] = scaler.fit_transform(X_train[numerical_continuous])
X_test[numerical_continuous] = scaler.transform(X_test[numerical_continuous])

"""## Modelling"""

import warnings
warnings.filterwarnings("ignore")

"""### Logistic Regression

- Menggunakan model Logistic Regression dengan parameter multi_class='multinomial' dan iterasi maksimum 5000 untuk memastikan konvergensi.

- Mendefinisikan grid hyperparameter untuk pencarian terbaik, meliputi:
  - `Regularisasi C` dengan nilai [0.01, 0.1, 1, 10].
  - `Jenis penalti`: l2, l1, dan elasticnet.
  - `Solver` yang digunakan: lbfgs, liblinear, dan saga.

- Memanfaatkan StratifiedKFold dengan 10 fold (saran dari dataset) dan shuffle untuk validasi silang yang menjaga distribusi kelas.
"""

lgr = LogisticRegression(multi_class='multinomial', max_iter=5000)

# Hyperparameter grid
logreg_param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2', 'l1', 'elasticnet'],
    'solver': ['lbfgs', 'liblinear', 'saga']
}
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

"""Melakukan pencarian hyperparameter terbaik menggunakan GridSearchCV dengan metrik evaluasi f1_macro dan menjalankan secara paralel (n_jobs=-1)."""

lgr_gridcv = GridSearchCV(lgr, logreg_param_grid, cv=skf, scoring='f1_macro', n_jobs=-1)
lgr_gridcv.fit(X_train, y_train)

print(f"Best Parameters: {lgr_gridcv.best_params_}")
print(f"Best Score: {lgr_gridcv.best_score_}")

"""Model dengan parameter terbaik disimpan sebagai model_lgr (Model Logistic Linear)"""

model_lgr = lgr_gridcv.best_estimator_
model_lgr

"""Melakukan prediksi pada data uji dan menampilkan laporan klasifikasi (classification report) untuk mengevaluasi performa model."""

y_pred_lgr = model_lgr.predict(X_test)
print(classification_report(y_test, y_pred_lgr))

"""Model mencapai akurasi 86% pada data uji, menunjukkan performa prediksi yang baik.
- Untuk kelas 0:

  - Precision 89%, artinya 89% prediksi kelas 0 benar.

  - Recall 86%, artinya 86% data aktual kelas 0 berhasil terdeteksi.

  - F1-score 87% sebagai keseimbangan precision dan recall.

- Untuk kelas 1:

  - Precision 81%, recall 86%, dan F1-score 84%, menunjukkan model juga efektif mendeteksi kelas ini.

Rata-rata makro (menghitung rata-rata tanpa memperhatikan proporsi kelas) F1-score adalah 85%, menandakan performa seimbang antar kelas.
Rata-rata tertimbang (weighted avg) juga 86%, memperhitungkan proporsi masing-masing kelas.

### Random Forest

- Menggunakan model Random Forest dengan parameter random_state=42.

- Mendefinisikan grid hyperparameter untuk pencarian terbaik, meliputi:
  - `n_estimators`: jumlah pohon di hutan, dengan opsi 100 dan 200.

  - `max_depth`: kedalaman maksimum pohon, opsi 3, 5, dan 10.

  - `min_samples_split`: minimum sampel untuk memecah node, 5 dan 10.

  - `min_samples_leaf`: minimum sampel pada daun, 2 dan 4.

  - `class_weight`: di-set menjadi 'balanced' untuk menangani ketidakseimbangan kelas.

- Memanfaatkan StratifiedKFold dengan 10 fold (saran dari dataset) dan shuffle untuk validasi silang yang menjaga distribusi kelas.
"""

rf = RandomForestClassifier(random_state=42)
rf_param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 10],
    'min_samples_split': [5, 10],
    'min_samples_leaf': [2, 4],
    'class_weight': ['balanced']
}
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

"""Melakukan pencarian hyperparameter terbaik menggunakan GridSearchCV dengan metrik evaluasi f1_macro dan menjalankan secara paralel (n_jobs=-1)."""

rf_gridcv = GridSearchCV(rf, rf_param_grid, cv=skf, scoring='f1_macro')
rf_gridcv.fit(X_train, y_train)

print(f"Best Parameters: {rf_gridcv.best_params_}")
print(f"Best Score: {rf_gridcv.best_score_}")

"""Model dengan parameter terbaik disimpan sebagai model_rf (Model Random Forest)"""

model_rf = rf_gridcv.best_estimator_
model_rf

y_pred_rf = model_rf.predict(X_test)
print(classification_report(y_test, y_pred_rf))

"""Model mencapai akurasi 86% pada data uji, menunjukkan performa prediksi yang baik.
- Untuk kelas 0:

  - Precision 93%, artinya 93% prediksi kelas 0 benar.

  - Recall 82%, artinya 82% data aktual kelas 0 berhasil terdeteksi.

  - F1-score 87% sebagai keseimbangan precision dan recall.

- Untuk kelas 1:

  - Precision 79%, recall 92%, dan F1-score 85%, menunjukkan model juga efektif mendeteksi kelas ini.

Rata-rata makro (menghitung rata-rata tanpa memperhatikan proporsi kelas) F1-score adalah 86%, menandakan performa seimbang antar kelas.
Rata-rata tertimbang (weighted avg) juga 86%, memperhitungkan proporsi masing-masing kelas.

## Evaluation Metrics

Melakukan Perbandingan antara F1 Score dan Akurasi pada model Logistic Regression dan Random Forest menggunakan visualisasi.
"""

accuracy_scores = {
    'Logistic Regression': accuracy_score(y_test, y_pred_lgr),
    'Random Forest': accuracy_score(y_test, y_pred_rf)
}

f1_scores = {
    'Logistic Regression': f1_score(y_test, y_pred_lgr, average='macro'),
    'Random Forest': f1_score(y_test, y_pred_rf, average='macro')
}

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# F1 Score Barplot
sns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()), ax=axes[0], palette='Greens')
axes[0].set_title("F1 Score Comparison")
axes[0].set_ylim(0, 1.05)
axes[0].set_ylabel("F1 Score")

for i, val in enumerate(f1_scores.values()):
    axes[0].text(i, val + 0.02, f"{val:.2f}", ha='center')

# Accuracy Barplot
sns.barplot(x=list(accuracy_scores.keys()), y=list(accuracy_scores.values()), ax=axes[1], palette='Blues')
axes[1].set_title("Accuracy Comparison")
axes[1].set_ylim(0, 1.05)
axes[1].set_ylabel("Accuracy")

for i, val in enumerate(accuracy_scores.values()):
    axes[1].text(i, val + 0.02, f"{val:.2f}", ha='center')

plt.tight_layout()
plt.show()

"""Melakukan perbandingan evaluasi metrik menggunakan Confusion Matrix dan divisualisasikan."""

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Logistic Regression
sns.heatmap(confusion_matrix(y_test, y_pred_lgr), annot=True, fmt='d', cmap='Greens', ax=axes[0])
axes[0].set_title("Logistic Regression - Confusion Matrix")
axes[0].set_xlabel("Predicted")
axes[0].set_ylabel("Actual")

# Random Forest
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title("Random Forest - Confusion Matrix")
axes[1].set_xlabel("Predicted")
axes[1].set_ylabel("Actual")

plt.tight_layout()
plt.show()

"""Berdasarkan hasil evaluasi dua model klasifikasi, yaitu Logistic Regression dan Random Forest, didapatkan nilai akurasi dan f1-score yang cukup dekat, yaitu Logistic Regression dengan akurasi 0.86 dan f1-score 0.85, serta Random Forest dengan akurasi 0.86 dan f1-score 0.86.

Namun demikian, analisis lanjutan melalui **confusion matrix** menunjukkan bahwa Random Forest memiliki jumlah **false negative (FN) yang lebih rendah**, yaitu 6 kasus, dibandingkan Logistic Regression yang mencatatkan 10 kasus. Dalam konteks prediksi medis, khususnya deteksi glioma, **false negative merupakan jenis kesalahan yang paling kritis**, karena kesalahan ini berarti pasien yang sebenarnya positif (mengidap glioma) tidak terdeteksi dan berisiko tidak mendapatkan penanganan yang tepat waktu.

Dengan mempertimbangkan bahwa **keselamatan pasien adalah prioritas utama**, maka **model Random Forest dipilih sebagai model terbaik** karena kemampuannya dalam meminimalkan kesalahan prediksi negatif palsu, yang sangat krusial dalam aplikasi nyata di bidang kesehatan.
"""